<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>

<head>
  <title>choices</title>
  <link rel="stylesheet" href="../styles/mystyles.css">
</head>

<body>


  <ul class="navbar">
    <li><a href="../index.html">Home page</a>
    <li><a href="topic.html">Technology/Topic</a>
    <li><a href="opportunities.html">Opportunities</a>
    <li><a href="risks.html">Risks</a>
    <li><a href="case-studies.html">Case Studies</a>
    <li><a href="choices.html">Choices</a>
    <li><a href="references.html">References</a>

  </ul>



  <h1>Technology Choices</h1>


  </ul>
  <h4>What choices do Soceity/The individual have when it comes to Generative AI</h4>

  <p class="main-text">
    When it comes to Generative AI in education there are several choices that society, individuals and educational
    institutions can make to adapt to this this new technology





  </p>
  <p class="main-text"> <b>Banning the use of AI </b>
    <br>
    <br>
    This option entails universities outright banning the use of tools like ChatGPT. The breach of which would be
    considered an academic integrity issue. Since both novice and experienced teachers could not
    meaningfully distinguish between text written by students or ChatGPT <a
      href="references.html#reference_3">(Fleckenstein, et al. 2024)</a>, detection would
    most likely rely on digital tools similar to existing tools that exist in higher education to detect
    plagiarism.However, even with current tools available educators are often not able to accurately detect AI generated
    content. <a href="references.html#reference_6">Perkins, et al. (2024)</a> reported that an AI detection tool
    detected
    only 54.5% of the AI generated
    submissions. While it can be argued that detection tools are likely to improve, the consensus is that the
    improvement of generative AI itself is also likely to improve<a href="references.html#reference_7">(Lee, et al. 2024
      )</a>. Sole focus on the improvement of
    these detection tools will likely lead to a cat and mouse game that favours generative AI.

    <br><br>
    Overall, while strict regulation affording the use of generative AI is important, sole reliance on detecting and
    punishing these actions often does not address the root cause of the problem. <a
      href="references.html#reference_1">Playfoot et al.(2024)</a> indicates that
    there is a correlation between degree apathy and likelihood of utilizing generative AI to cheat.This suggests that
    generative AI does not increase the amount of academic dishonesty but simply provides another tool for people who do
    not care about learning to dishonestly obtain their degree.
    <br><br>
    However, while cases such as generating entire essays via ChatGPT obviously falls under academic dishonesty, there
    are many use cases of the technology that would not necessarily be academic dishonesty. <a
    href="references.html#reference_9">AlAfnan et al (2023)</a>  finds
    that ChatGPT rivals search engines in terms of providing answers to theory-based questions. This means that students
    could use ChatGPT to further understanding.

    <br><br>

    The Joint task force between the Modern Language Association and the Conference on College Composition and
    Communication further outlines many cases where students may use generative AI to further understanding. This
    includes generating sample texts following certain styles or constraints in order to illustrate examples or allowing
    those not versed in a language to express their own ideas more easily<a
    href="references.html#reference_10">(MLA-CCC Joint Task Force, 2023)</a>  . These are
    examples of situations where the use of generative AI would help rather than hinder the learning of students. A
    blanket ban on generative AI would discourage the use of a key learning tool that may benefit many students’
    education.

    <br><br>

    To this end, the task force recommends an approach to academic integrity that is “a collaborative rather than
    adversarial” and “support students rather than punish them.” Educators that utilize AI detection tools need to
    consider the possibility of a false positive and how such an accusation would affect a student. To that end AI
    literacy is particularly important not only in showing students what constitutes academic dishonesty when utilizing
    AI tools but also for teachers to understand the limitation and accuracy of the detection tools. <!--  -->
    <br><br>

    A blanket ban on AI stops students from getting any of the benefits of AI in their learning

    however it ensures that students work is their own and not written by a model. All choices offer both advantages and
    disadvantages. In this case, it is clear that a ban on generative AI in higher education yields more disadvantages
    than advantages.
    <br><br>
  </p>
  <img src="img03.png"><br>
  <p style="font-size: small;"><a href="references.html#reference_8">(Concept of Online Education. Man Use Online
      Education Training, 2023)</a>.</p>

  As a wider society we also have a lot of say on its usage weather we want to adapt it to become a part of all our
  lives or limit its usage to protect us from its ethical issues. These choices must come from governmental or global
  bodies to ensure coordination and ensure that ethical concerns are managed appropriately.
  </p>

</html>