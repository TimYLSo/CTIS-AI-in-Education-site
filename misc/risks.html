<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>

<head>
	<title>risks</title>
	<link rel="stylesheet" href="../styles/mystyles.css">
</head>

<body>

	<ul class="navbar">
		<li><a href="../index.html">Home page</a>
		<li><a href="topic.html">Technology/Topic</a>
		<li><a href="opportunities.html">Opportunities</a>
		<li><a href="risks.html">Risks</a>
		<li><a href="case-studies.html">Case Studies</a>
		<li><a href="choices.html">Choices</a>
		<li><a href="references.html">References</a>
	</ul>

	<h1>Technology Risks</h1>


	</ul>
	<h4>
		<p>Recent Advancements in AI raise many ethical Concerns
		<p>
	</h4>
	<p class="main-text">
		The swift introduction of Generative AI into education has prompted many institutions to ban its usage while
		they evaluate the ethics of its systems and impacts on learning in their institutions.
		These ethical considerations are important as the decisions of these educational institutions with influence
		society in the long term as students graduate and pass their habits into academia and or the workforce.
		Two studies from the International Journal of Educational Technology in Higher Education(<a
			href="references.html#reference_5">Abbas, Muhammad, 2024</a>)
		sampled 659 students in total and found that students who frequently used ChatGPT in their work had a lower CGPA
		(Cumulative Grade Points Average).
		This correlation calls into question students' reliance on such tools and the quality of understanding they
		present.
		From this information itâ€™s clear why many universities have banned its usage as they want to maintain the
		quality of their students and academia.
	</p>
	<br><br>
	<img src="./img04.png">
	<p style="font-size: small">(ChatGPT. Phone with ChatGPT logo infront of ChatGPT website, 2023)</p>
	<p class="main-text">
		Another key issue with Generative AI highlighted in Investigating the Impact of AI on Ethics and Spirituality
		(<a href='references.html#reference_120"'>Swati Chakraborty, 2023, c. 2</a>) is its adaptation
		of human bias.
		The data used to train these Generative AI is scraped from the internet in massive quantities which makes it
		extremely difficult to filter prejudice and misinformation.
		Quiet often these models pass this bias into their responses in subtle ways.
		These biases can be passed into academia, the workplace and wider society.
		Ironically it can also be passed back into the model when work made using AI is published, enforcing its already
		existing bias.
		These biases are quite often harmful to society as they can misrepresent underrepresented groups and give false
		impression of someone's beliefs.

	</p>
	<p class="main-text"><b>Over-reliance on AI </b>



		Over reliance on AI in education can lead to challenges both for students and educators. AI can provide with
		answers and support. However, it may not address personal needs of each student as educator can do. This
		dependency can also reduce the chances of students to get skills such as critical thinking and problem-solving
		ones. Furthermore, reliance on ai can overshadow the importance of mentorship in the learning process which is
		essential.
		<br><br>
		Integration of AI should be balanced with traditional teaching methods to maintain a quality learning
		environment.
		<br><br>
		AI Hallucination



		AI technology can monitor each student's progress and offer personalised feedback, justification, and guidance.
		With personalised learning systems, students can achieve their learning goals at a pace suited to their
		abilities. However, using AI, such as chatbots, for learning guidance often introduces errors and issues. These
		can lead to subtle AI hallucinations and biases that skew the generated responses, resulting in incorrect
		learning guidance. This is a common problem that needs addressing, as inaccurate guidance can make the learning
		system ineffective. (<a
		href="references.html#reference_55">(SusantoE, Halim, Richard, A. Gui & Nelly,2023)</a>)



		Artificial intelligence hallucination is a significant risk in educational settings, where AI models may
		generate unexpected and incorrect results. This phenomenon occurs when AI algorithms and deep learning neural
		networks produce outputs that do not align with the data they were trained on or follow any discernible pattern.
		In education, AI hallucinations can lead to the creation of false information, such as inaccurate news articles,
		historical accounts, or scientific facts. For instance, an AI tool like ChatGPT might fabricate a fake biography
		for a historical figure, which could spread rapidly and mislead students. This risk becomes particularly
		concerning in the context of AI-powered learning systems, where students rely on accurate guidance to achieve
		their educational goals. If the AI provides incorrect or biased information, it undermines the effectiveness of
		the learning system and can lead to significant misunderstandings. Addressing AI hallucinations is crucial to
		ensure that AI tools enhance learning rather than detract from it.
	</p>

</html>