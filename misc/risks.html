<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>

<head>
	<title>risks</title>
	<link rel="stylesheet" href="../styles/mystyles.css">
</head>

<body>
<!-- Site navigation menu -->

<ul class="navbar">
  <li><a href="../index.html">Home page</a>
  <li><a href="topic.html">Technology/Topic</a>
	<li><a href="opportunities.html">Opportunities</a>
	<li><a href="risks.html">Risks</a>
  <li><a href="case-studies.html">Case Studies</a>
	<li><a href="choices.html">Choices</a>
	<li><a href="references.html">References</a>
    
</ul>

	<h1>Technology Risks</h1>


	</ul>
	<h4>
		<p>Recent Advancements in AI raise many ethical Concerns
		<p>
	</h4>
	<p class="main-text">
		The swift introduction of Generative AI into education has prompted many institutions to ban its usage while
		they evaluate the ethics of its systems and impacts on learning in their institutions.
		These ethical considerations are important as the decisions of these educational institutions with influence
		society in the long term as students graduate and pass their habits into academia and or the workforce.
		Two studies from the International Journal of Educational Technology in Higher Education(<a
			href='https://link.springer.com/content/pdf/10.1186/s41239-024-00444-7.pdf'>Abbas, Muhammad, 2024</a>)
		sampled 659 students in total and found that students who frequently used ChatGPT in their work had a lower CGPA
		(Cumulative Grade Points Average).
		This correlation calls into question students' reliance on such tools and the quality of understanding they
		present.
		From this information itâ€™s clear why many universities have banned its usage as they want to maintain the
		quality of their students and academia.
		<br>
		<br>
		Another key issue with Generative AI highlighted in Investigating the Impact of AI on Ethics and Spirituality
		(<a href='https://www.igi-global.com/gateway/book/318133'>Swati Chakraborty, 2023, c. 2</a>) is its adaptation
		of human bias.
		The data used to train these Generative AI is scraped from the internet in massive quantities which makes it
		extremely difficult to filter prejudice and misinformation.
		Quiet often these models pass this bias into their responses in subtle ways.
		These biases can be passed into academia, the workplace and wider society.
		Ironically it can also be passed back into the model when work made using AI is published, enforcing its already
		existing bias.
		These biases are quite often harmful to society as they can misrepresent underrepresented groups and give false
		impression of someone's beliefs.
	</p>

 </html>
</html>
